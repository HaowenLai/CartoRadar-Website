<!DOCTYPE html>
<html>

<head>
  <!-- When developing, comment this tag to use relative path. -->
  <!-- When publishing, uncomment this base tag and change to the Github repo path. -->
  <base href="https://cdn.jsdelivr.net/gh/HaowenLai/CartoRadar-Website@latest/">

  <meta charset="utf-8">
  <meta name="description" content="CartoRadar: RF-Based 3D SLAM Rivaling Vision Approaches">
  <meta name="keywords" content="CartoRadar, RF-based SLAM, Localization, Mapping, mmWave Radar, Uncertainty Quantification, Robust Perception, Machine Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CartoRadar: RF-Based 3D SLAM Rivaling Vision Approaches</title>

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="icon" href="resources/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <!-- Navigation Bar -->
  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://haowenlai.github.io">
          <span class="icon"><i class="fas fa-home"></i></span>
        </a>
  
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">More Research</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://waves.seas.upenn.edu/projects/panoradar">PanoRadar</a>
            <a class="navbar-item" href="https://waves.seas.upenn.edu/projects/cartoradar">CartoRadar</a>
          </div>
        </div>
      </div>
    </div>
  </nav>
</head>

<body>
<section class="hero" id="top">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">CartoRadar: RF-Based 3D SLAM Rivaling Vision Approaches</h1>
          <div class="is-size-4 publication-authors">
            <span class="author-block">
              <a href="https://haowenlai.github.io" target="_blank">Haowen Lai*</a>&nbsp;&nbsp;&nbsp;&nbsp;
              <a href="https://zhiwei-zzz.github.io/" target="_blank">Zhiwei Zheng*</a>&nbsp;&nbsp;&nbsp;&nbsp;
              <a href="https://www.cis.upenn.edu/~mingminz" target="_blank">Mingmin Zhao</a>
              <br/> University of Pennsylvania
              <span class="brmod"><strong><a href="https://www.sigmobile.org/mobicom/2025/" target="_blank">MobiCom 2025</a></strong></span>
              <br/>
              <div>
                <img src='resources/images/artifacts_available_v1_1.png' width=100px>
                <img src='resources/images/artifacts_evaluated_functional_v1_1.png' width=100px>
                <img src='resources/images/artifacts_evaluated_reusable_v1_1.png' width=100px>
                <img src='resources/images/results_reproduced_v1_1.png' width=100px>
              </div>
            </span>
          </div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="" 
                   class="external-link button is-normal is-rounded is-dark" target="_blank">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- ACM Digital Library. -->
              <!-- <span class="link-block">
                <a href="xxxx"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-acmdl"></i>
                  </span>
                  <span>ACM DL</span>
                </a>
              </span> -->
              <!-- Arxiv Link. -->
              <!-- <span class="link-block">
                <a href="xxxx"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <span class="link-block">
                <a class="external-link button is-normal is-rounded is-dark jump-in-page" data-target="demo-video">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark" target="_blank">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark" target="_blank">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
              <!-- News Link. -->
              <!-- <span class="link-block">
                <a href="https://ai.seas.upenn.edu/news/giving-robots-superhuman-vision-using-radio-signals"
                   class="external-link button is-normal is-rounded is-dark" target="_blank">
                  <span class="icon">
                      <i class="far fa-solid fa-newspaper"></i>
                  </span>
                  <span>News</span>
                </a>
              </span> -->
              <!-- Slides Link. -->
              <!-- <span class="link-block">
                <a href="xxxx"
                   class="external-link button is-normal is-rounded is-dark" target="_blank">
                  <span class="icon">
                      <i class="fa fa-list"></i>
                  </span>
                  <span>Slides (coming soon)</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser Figure -->
<section class="hero">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img class="teaser" src="resources/images/teaser.png" alt="Teaser Image" width="600px">
      <div class="has-text-centered">
        CartoRadar enables high-fidelity 3D SLAM using a mmWave radar as the robot navigates through a building.
        It leverages RF signals to simultaneously (a) localize the robot and (b) build a 3D map of the environment.
        It captures (c) high-fidelity details, on par with vision baselines.
        Note the highlighted glass window, which is successfully reconstructed by our method but missed by all vision baselines.
      </div>
    </div>
  </div>
</section>


<!-- Abstract -->
<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h3 class="title is-3">Abstract</h3>
        <div class="content has-text-justified">
          <p>
            We present CartoRadar, a novel RF-based SLAM system that delivers high-fidelity 3D mapping with centimeter-level accuracy. 
            CartoRadar builds on top of the advancements in learning-based RF imaging. 
            However, learning-based systems often exhibit variation in prediction accuracy during inference. 
            To address this challenge and enable robust RF sensing, CartoRadar introduces a novel, training-free uncertainty quantification method tailored to RF signals.
            Additionally, CartoRadar features an efficient SLAM algorithm that incorporates this uncertainty into the mapping process.
            We deploy CartoRadar on a mobile robot and conduct extensive evaluations across 14 floors in 5 buildings.
            Results show that CartoRadar achieves a trajectory error of 14.1 cm, outperforming camera-based baselines by 72.1%.
            For mapping, CartoRadar achieves an accuracy of 7.4 cm and a completion of 8.1 cm, improving over vision methods by 46.2% and 67.6%, respectively.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Paper video. -->
<section class="section">
  <div class="container">
    <div id="demo-video" class="columns is-centered has-text-centered">
      <div class="column is-three-quarters">
        <h3 class="title is-3">Demo Video</h3>
        <div class="publication-video">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/WRiaRZXQ4gM?si=vz9Uj9u9xJ57GbSX" title="YouTube video player"
                  frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                  referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
          </iframe>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Overview -->
<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h3 class="title is-3">System Overview</h3>
        <div class="content has-text-centered">
          <img class="teaser" src="resources/images/overview.png" alt="Overview Image" width="700px">
        </div>
        <div class="content has-text-justified">
          <p>This figure illustrates the system architecture of CartoRadar, consisting of two components:</p>
          <ol>
            <li><strong>Robust RF Sensing with Uncertainty quantification</strong> takes in the raw RF signals and outputs range images with uncertainty estimates for each pixel.</li>
            <li><strong>Uncertainty-aware RF-Based SLAM</strong> takes in the predicted range images and incorporates the uncertainty estimates into the SLAM process.
              We propose a novel implicit occupancy field with probabilistic learning, effectively improving the accuracy, robustness and efficiency.
            </li>
          </ol>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Uncertainty Quantification -->
<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h3 class="title is-3">Robust RF Sensing with Uncertainty quantification</h3>
        <table style="border-collapse: collapse; width: 100%; text-align: center; font-family: Arial, sans-serif;">
  <thead>
    <tr style="border-bottom: 2px solid #333;">
      <th rowspan="2"></th>
      <th colspan="6">Re-train Required</th>
      <th></th>
      <th colspan="2">Out-of-the-box</th>
      <th></th>
      <th colspan="2">Re-train Required</th>
    </tr>
        <tr style="border-bottom: 2px solid #333;">
          <th>Lap.</th>
          <th>Ens.-4</th>
          <th>Ens.-8</th>
          <th>Ens.-12</th>
          <th>Drop.-32</th>
          <th>Drop.-128</th>
          <th></th>
          <th>Ours-16</th>
          <th>Ours-32</th>
          <th></th>
          <th>OursH-16</th>
          <th>OursH-32</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><b>NLL↓</b></td>
          <td>0.97</td>
          <td>0.46</td>
          <td>-0.09</td>
          <td>-0.12</td>
          <td>1.11</td>
          <td>1.00</td>
          <td></td>
          <td>-0.80</td>
          <td>-0.82</td>
          <td></td>
          <td>-0.93</td>
          <td><b>-0.94</b></td>
        </tr>
        <tr>
          <td><b>AUSE↓</b></td>
          <td>0.96</td>
          <td>1.20</td>
          <td>0.99</td>
          <td>0.87</td>
          <td>0.92</td>
          <td>0.87</td>
          <td></td>
          <td>0.80</td>
          <td>0.74</td>
          <td></td>
          <td>0.75</td>
          <td><b>0.70</b></td>
        </tr>
        <tr style="border-top: 2px solid #333;">
          <td><b>#Trained Models</b></td>
          <td>1</td>
          <td>4</td>
          <td>8</td>
          <td>12</td>
          <td>1</td>
          <td>1</td>
          <td></td>
          <td><b>0</b></td>
          <td><b>0</b></td>
          <td></td>
          <td>1</td>
          <td>1</td>
        </tr>
      </tbody>
    </table>

        <div class="content has-text-justified">
          <br>
          <p>
            We compare our proposed uncertainty quantification methods with three baselines and report the NLL and AUSE results in the table above.
            Our method can be applied out of the box, without any re-training, and still achieves better performance than the traditional baseline methods.
            Furthermore, with one additional training step, our method can achieve even greater performance improvements.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Qualitative Results -->
<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h3 class="title is-3">Uncertainty-aware RF-Based SLAM</h3>
        <img class="teaser" src="resources/images/QualResult.png" width="1200px">
        <div class="content has-text-justified">
          <br>
          <p>
            We present the mapping results (left) and detailed views (right) of CartoRadar across different environments.
            For each trajectory, our results are compared with the corresponding LiDAR mesh map.
            The maps are color-coded according to surface normals, and the trajectories are shown as yellow lines.
            We also provide accompanying videos for better visualization and zoomed-in views of details.
          </p>
        </div>

        <h4 class="title is-4">Overall Localization and Mapping</h4>
        <div class="comparisons-row">
          <!-- Scene Comparison 1 -->
          <div class="comparison">
            <div class="pair">
              <video autoplay loop muted playsinline preload="metadata">
                <source src="resources/videos/mesh_levine_001_our.mp4" type="video/mp4">
              </video>
              <video autoplay loop muted playsinline preload="metadata">
                <source src="resources/videos/mesh_levine_001_gt.mp4" type="video/mp4">
              </video>
            </div>
            <div class="cap">Scene 1: Ours vs. Ground Truth</div>
          </div>
          <!-- Scene Comparison 2 -->
          <div class="comparison">
            <div class="pair">
              <video autoplay loop muted playsinline preload="metadata">
                <source src="resources/videos/mesh_levineN_001_our.mp4" type="video/mp4">
              </video>
              <video autoplay loop muted playsinline preload="metadata">
                <source src="resources/videos/mesh_levineN_001_gt.mp4" type="video/mp4">
              </video>
            </div>
            <div class="cap">Scene 2: Ours vs. Ground Truth</div>
          </div>
      </div>
      <br>

      <h4 class="title is-4">High-Fidelity Details</h4>
      <div class="comparisons-row">
          <!-- Details Comparison 1 -->
          <div class="comparison">
            <div class="pair">
              <video autoplay loop muted playsinline preload="metadata">
                <source src="resources/videos/detail_levine001_1_our.mp4" type="video/mp4">
              </video>
              <video autoplay loop muted playsinline preload="metadata">
                <source src="resources/videos/detail_levine001_1_gt.mp4" type="video/mp4">
              </video>
            </div>
            <div class="cap">Pillars: Ours vs. Ground Truth</div>
          </div>

          <!-- Comparison 2 -->
          <div class="comparison">
            <div class="pair">
              <video autoplay loop muted playsinline preload="metadata">
                <source src="resources/videos/detail_levine001_2_our.mp4" type="video/mp4">
              </video>
              <video autoplay loop muted playsinline preload="metadata">
                <source src="resources/videos/detail_levine001_2_gt.mp4" type="video/mp4">
              </video>
            </div>
            <div class="cap">Chairs: Ours vs. Ground Truth</div>
          </div>
      </div>

      <div class="comparisons-row">
          <!-- Comparison 1 -->
          <div class="comparison">
            <div class="pair">
              <video autoplay loop muted playsinline preload="metadata">
                <source src="resources/videos/detail_moore002_1_our.mp4" type="video/mp4">
              </video>
              <video autoplay loop muted playsinline preload="metadata">
                <source src="resources/videos/detail_moore002_1_gt.mp4" type="video/mp4">
              </video>
            </div>
            <div class="cap">Stairs: Ours vs. Ground Truth</div>
          </div>

          <!-- Comparison 2 -->
          <div class="comparison">
            <div class="pair">
              <video autoplay loop muted playsinline preload="metadata">
                <source src="resources/videos/detail_moore002_2_our.mp4" type="video/mp4">
              </video>
              <video autoplay loop muted playsinline preload="metadata">
                <source src="resources/videos/detail_moore002_2_gt.mp4" type="video/mp4">
              </video>
            </div>
            <div class="cap">Walls: Ours vs. Ground Truth</div>
          </div>
      </div>
    </div>
  </div>
</section>


<!-- Code and Dataset -->
<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h3 class="title is-3">Code and Dataset</h3>
        <div class="content has-text-justified">
          <p>
            Our system is evaluated over 14 floors across 5 separate buildings.
            The diversity of the buildings is notable, featuring distinct designs and materials with construction dates stretching from 1906 to 2006.
            The entire dataset was collected traversing a distance of 1527 meters.
            After signal processing, it consists of 6637 synchronized RF and LiDAR frames, respectively, aggregating to 223 GB.
          </p>
          <p>
            We will release code and dataset to facilitate future research in this direction.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- BibTeX citation -->
<section class="section" id="BibTeX">
  <div class="container">
    <h3 class="title is-3">BibTeX</h3>
    <div class="content has-text-justified">
      <p>If you find <a class="jump-in-page" data-target="top">CartoRadar</a> method or dataset useful for your work, please consider citing:</p>
    </div>
    <pre><code>@inproceedings{cartoradar,
  title={RF-Based 3D SLAM Rivaling Vision Approaches},
  author={Lai, Haowen and Zheng, Zhiwei and Zhao, Mingmin},
  booktitle={Proceedings of the 31th Annual International Conference on Mobile Computing and Networking (MobiCom)},
  year={2025}
}</code></pre>
    <div class="content has-text-justified">
      <br>
      <p>If our rotating radar design inspires your work, please consider citing <a href="https://waves.seas.upenn.edu/projects/panoradar" target="_blank">PanoRadar</a>:</p>
    </div>
    <pre><code>@inproceedings{panoradar,
  title={Enabling Visual Recognition at Radio Frequency},
  author={Lai, Haowen and Luo, Gaoxiang and Liu, Yifei and Zhao, Mingmin},
  booktitle={Proceedings of the 30th Annual International Conference on Mobile Computing and Networking (MobiCom)},
  pages={388--403},
  year={2024}
}</code></pre>
  </div>
</section>


<!-- Acknowledgements -->
<section class="section" id="Acknowledgements">
  <div class="container">
    <h3 class="title is-3">Acknowledgments</h3>
      <div class="is-vcentered interpolation-panel">
        <p>
          This work was carried out in the <a href="https://waves.seas.upenn.edu" target="_blank">WAVES Lab</a>, University of Pennsylvania.
          We sincerely thank the anonymous reviewers and our shepherd for their insightful comments.
          We are grateful for the feedbacks provided by Xin Yang, Zitong Lan, Dongyin Hu, and Yiduo Hao.
        </p>
        <br/>
        <p>This project page template is adapted from <a href="https://nerfies.github.io" target="_blank">Nerfies</a>.</p>
      </div>
  </div>
</section>

<br/>
<br/>
<br/>

<!-- <footer class="footer">
  <div class="container">
    <div class="content has-text-centered"></div>
  </div>
</footer> -->

</body>
</html>
